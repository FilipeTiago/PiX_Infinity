#!/usr/bin/env python3
import os, sys, json, subprocess, re, pathlib, urllib.parse, tempfile, shutil, time
from html import escape

# ---------------- Env knobs ----------------
DEBUG           = os.environ.get("PIX_YT_DEBUG","0") == "1"   # extra yt-dlp logs
IPV4            = os.environ.get("PIX_YT_IPV4","0") == "1"
COOKIES_PROFILE = os.environ.get("PIX_YT_COOKIES_PROFILE","").strip() or None
FETCH_AVATAR    = os.environ.get("PIX_YT_FETCH_AVATAR","1") == "1"  # avatar ON by default
YT_TIMEOUT      = int(os.environ.get("PIX_YT_TIMEOUT", "60"))       # per yt-dlp JSON call
YT_TIMEOUT_AV   = int(os.environ.get("PIX_YT_TIMEOUT_AVATAR", str(max(90, int(os.environ.get("PIX_YT_TIMEOUT","60"))))))
MAX_PL_PER_CH   = int(os.environ.get("PIX_YT_MAX_PLAYLISTS", "0"))  # 0 = no cap

# ---------------- Logging helpers ----------------
def dbg(m):
    if DEBUG: print(m, flush=True)

def say(m):
    print(m, flush=True)

def playlist_embed_url(url: str) -> str:
    u = urllib.parse.urlparse(url)
    q = urllib.parse.parse_qs(u.query)
    pid = (q.get("list") or [""])[0]
    if not pid:
        return url
    # Autoplay + clean chrome; plays inside the player immediately
    return (
        f"https://www.youtube.com/embed/videoseries"
        f"?list={pid}&autoplay=1&rel=0&iv_load_policy=3&modestbranding=1&playsinline=1"
    )

def first_video_id_for_playlist(url: str) -> str | None:
    """Return first video id in playlist or None on failure/timeout."""
    # Use the same cookies/IPv4 knobs and client order we already use
    orders = [("web", bool(COOKIES_PROFILE))]
    if not COOKIES_PROFILE:
        orders.append(("android", False))
    for client, use_cookies in orders:
        j = ytdlp_json(url, client=client, flat=True, use_cookies=use_cookies, timeout=min(30, YT_TIMEOUT))
        if not j: 
            continue
        entries = j.get("entries") or []
        for e in entries:
            vid = (e.get("id") or "").strip()
            if vid and len(vid) in (11, 12):  # typical YT video ID length
                return vid[:11]
    return None

def watch_url_for_playlist(playlist_url: str) -> str:
    """Build a watch URL that starts the playlist immediately."""
    pid = urllib.parse.parse_qs(urllib.parse.urlparse(playlist_url).query).get("list", [""])[0]
    if not pid:
        return playlist_url
    vid = first_video_id_for_playlist(playlist_url)
    if vid:
        u = urllib.parse.urlparse("https://www.youtube.com/watch")
        q = urllib.parse.urlencode({"v": vid, "list": pid, "autoplay": "1"})
        return urllib.parse.urlunparse((u.scheme,u.netloc,u.path,"",q,""))
    # Fallback to embed videoseries (still autoplays if allowed)
    u = urllib.parse.urlparse("https://www.youtube.com/embed/videoseries")
    q = urllib.parse.urlencode({
        "list": pid, "autoplay": "1", "rel": "0",
        "iv_load_policy": "3", "modestbranding": "1", "playsinline": "1"
    })
    return urllib.parse.urlunparse((u.scheme,u.netloc,u.path,"",q,""))


# ---------------- Subprocess wrappers ----------------
def run_json(cmd, timeout):
    dbg(f"[yt-sync] yt-dlp call: {' '.join(cmd)}")
    try:
        p = subprocess.run(cmd, text=True, capture_output=True, timeout=timeout)
    except subprocess.TimeoutExpired:
        say(f"[yt-sync] TIMEOUT after {timeout}s: {' '.join(cmd[-3:])}")
        return None
    if p.returncode != 0:
        err = (p.stderr or "").strip().replace("\n"," ")
        err = re.sub(r"\s+", " ", err)[:400]
        dbg(f"[yt-sync] yt-dlp ERR {p.returncode}: {err}")
        return None
    try:
        return json.loads(p.stdout)
    except Exception:
        dbg("[yt-sync] parse error on yt-dlp JSON")
        return None

def ytdlp_json(url, *, client="web", flat=True, use_cookies=False, timeout=YT_TIMEOUT):
    args = ["yt-dlp", "-J", url, "--no-download", "--ignore-no-formats-error"]
    if IPV4: args.insert(1, "-4")
    if flat: args.insert(1, "--flat-playlist")
    if use_cookies and COOKIES_PROFILE:
        args += ["--cookies-from-browser", f"chromium:{COOKIES_PROFILE}"]
        client = "web"  # cookies only with web
    else:
        # Minimal consent cookie for anon scraping
        args += ["--add-header","Cookie: CONSENT=YES+cb.20210328-17-p0.en+FX+681"]
    args += ["--extractor-args", f"youtube:player_client={client}"]
    return run_json(args, timeout=timeout)

# ---------------- Name & path helpers ----------------
SAFE = re.compile(r"[^A-Za-z0-9._ \-]+")
def safename(s: str) -> str:
    s = re.sub(r"\s+", " ", s).strip()
    s = SAFE.sub("_", s)
    return s[:120].rstrip("._-") or "untitled"

def rom_root():
    try:
        p = subprocess.check_output(["pix_rom_location","youtube"], text=True).strip()
        if p: return pathlib.Path(p)
    except Exception: pass
    return pathlib.Path.home()/"RetroPie/roms/youtube"

def chan_base(url: str) -> str:
    u = url.strip()
    if u.startswith("@"): return f"https://www.youtube.com/{u}"
    if "youtube.com" in u: return u
    return f"https://www.youtube.com/@{u}"

def is_playlist_url(u: str) -> bool:
    return ("playlist?list=" in u) or ("list=" in urllib.parse.urlparse(u).query)

# ---------------- HTTP + image helpers ----------------
def curl_get(url, out_path):
    cmd = ["curl","-fsSL","--retry","3","--retry-delay","1","-o", str(out_path), url]
    return subprocess.run(cmd).returncode == 0

def convert_to_jpg(src, dst):
    return subprocess.run(["convert", str(src), str(dst)]).returncode == 0

def fetch_thumb_to_jpg(url, jpg_path):
    jpg_path = pathlib.Path(jpg_path)
    jpg_path.parent.mkdir(parents=True, exist_ok=True)
    # Skip if already there & non-empty
    try:
        if jpg_path.exists() and jpg_path.stat().st_size > 0:
            return True
    except Exception:
        pass
    with tempfile.TemporaryDirectory() as td:
        tmp = pathlib.Path(td)/"raw.img"
        if not curl_get(url, tmp):
            return False
        if not convert_to_jpg(tmp, jpg_path):
            try:
                shutil.copy(tmp, jpg_path); return True
            except Exception:
                return False
    return True

# ---------------- Playlist & avatar extraction ----------------
def extract_playlists_from_json(j):
    out = []
    if not j: return out
    entries = j.get("entries") or []
    for e in entries:
        title = e.get("title") or e.get("alt_title") or ""
        url   = e.get("url") or e.get("webpage_url") or ""
        if not url:
            pid = (e.get("id") or "")
            if pid and pid.startswith("PL"):
                url = f"https://www.youtube.com/playlist?list={pid}"
        if not url: continue
        if "list=" not in urllib.parse.urlparse(url).query:  # ensure playlist
            continue
        pid = urllib.parse.parse_qs(urllib.parse.urlparse(url).query).get("list", [""])[0]
        if not pid: continue

        # thumb (best)
        thumb = ""
        ths = e.get("thumbnails") or []
        if isinstance(ths, list) and ths:
            ths = sorted(ths, key=lambda t: t.get("width",0)*t.get("height",0), reverse=True)
            thumb = ths[0].get("url") or ""

        uploader = e.get("uploader") or e.get("channel") or ""
        out.append({"title": title or pid, "url": url, "playlist_id": pid, "thumb": thumb, "uploader": uploader})
    return out

def list_playlists_for_channel(base_url: str):
    # Prefer web+cookies if provided; else try android first, then web
    orders = [("web", True)] if COOKIES_PROFILE else [("android", False), ("web", False)]

    say("    • listing playlists tab …")
    for client, use_cookies in orders:
        j = ytdlp_json(base_url.rstrip("/") + "/playlists", client=client, flat=True, use_cookies=use_cookies, timeout=YT_TIMEOUT)
        pls = extract_playlists_from_json(j)
        if pls: return pls

    say("    • listing from channel page …")
    for client, use_cookies in orders:
        j = ytdlp_json(base_url, client=client, flat=True, use_cookies=use_cookies, timeout=YT_TIMEOUT)
        pls = extract_playlists_from_json(j)
        if pls: return pls

    return []

def get_channel_avatar_url(base_url: str):
    if not FETCH_AVATAR:
        dbg("[yt-sync] avatar: skipped (PIX_YT_FETCH_AVATAR=0)")
        return None
    say("    • fetching avatar …")
    j = ytdlp_json(base_url, client="web", flat=False, use_cookies=bool(COOKIES_PROFILE), timeout=YT_TIMEOUT_AV)
    if not j:
        say("      - avatar: none (timeout or parse fail)")
        return None
    for key in ("uploader_thumbnails","channel_thumbnails","thumbnails"):
        ths = j.get(key)
        if isinstance(ths, list) and ths:
            ths = sorted(ths, key=lambda t: t.get("width",0)*t.get("height",0), reverse=True)
            url = ths[0].get("url")
            if url:
                say("      - avatar: url ok")
                return url
    say("      - avatar: not found")
    return None

# For single playlist lines inside channels.txt
def probe_playlist_meta(url: str):
    say("      - probing playlist meta …")
    j = ytdlp_json(url, client="web", flat=False, use_cookies=bool(COOKIES_PROFILE), timeout=YT_TIMEOUT)
    if not j and not COOKIES_PROFILE:
        j = ytdlp_json(url, client="android", flat=False, use_cookies=False, timeout=YT_TIMEOUT)
    if not j:
        say("        × meta failed")
        return None
    title = j.get("title") or j.get("playlist_title") or "Playlist"
    uploader = j.get("uploader") or j.get("channel") or j.get("uploader_id") or "Playlists"
    ths = j.get("thumbnails") or j.get("playlist_thumbnails") or []
    thumb = ""
    if ths:
        ths = sorted(ths, key=lambda t: t.get("width",0)*t.get("height",0), reverse=True)
        thumb = ths[0].get("url") or ""
    say("        ✓ meta ok")
    return {"title": title, "uploader": uploader, "thumb": thumb, "url": url}

# ---------------- Channels file & gamelist ----------------
def read_channels(ch_file: pathlib.Path):
    if not ch_file.exists(): return []
    out=[]
    for ln in ch_file.read_text(encoding="utf-8", errors="ignore").splitlines():
        ln = ln.strip()
        if ln and not ln.startswith("#"): out.append(ln)
    return out

def write_root_gamelist(root: pathlib.Path, entries, folders_meta):
    gl = root / "gamelist.xml"
    lines = ['<?xml version="1.0"?>','<gameList>']

    # 1) Channel folders (avatars)
    for ch in sorted(folders_meta):
        meta = folders_meta[ch]
        rel_folder = f"./{ch}"
        disp_name = meta.get("name") or ch
        img_abs   = meta.get("image_abs") or ""
        lines.append("  <folder>")
        lines.append(f"    <path>{escape(rel_folder)}</path>")
        lines.append(f"    <name>{escape(disp_name)}</name>")
        if img_abs:
            lines.append(f"    <image>{escape(img_abs)}</image>")
        lines.append("  </folder>")

    # 2) Playlist entries
    for e in entries:
        lines.append("  <game>")
        lines.append(f"    <path>./{escape(e['relpath'])}</path>")
        lines.append(f"    <name>{escape(e['name'])}</name>")
        if e.get("image_abs"):
            lines.append(f"    <image>{escape(e['image_abs'])}</image>")
        lines.append("  </game>")

    lines.append("</gameList>")
    gl.write_text("\n".join(lines)+"\n", encoding="utf-8")

# ---------------- Main ----------------
def main():
    root = rom_root()
    root.mkdir(parents=True, exist_ok=True)

    chfile = root / "channels.txt"
    channels = read_channels(chfile)
    if not channels:
        say(f"[yt-sync] No channels in {chfile} (add @handle / channel URL / playlist URL)")
        return 0

    say(f"[yt-sync] Using cookies: {'Yes' if COOKIES_PROFILE else 'No'}   IPv4: {'Yes' if IPV4 else 'No'}   Avatars: {'Yes' if FETCH_AVATAR else 'No'}")
    dlroot = pathlib.Path.home()/".emulationstation/downloaded_images/youtube"

    all_entries = []
    folders_meta = {}  # channel_folder -> {name, image_abs}
    total = len(channels)

    for ci, entry in enumerate(channels, 1):
        if is_playlist_url(entry):
            say(f"[{ci}/{total}] Playlist URL: {entry}")
            meta = probe_playlist_meta(entry)
            if not meta:
                continue
            chan_folder = safename(meta["uploader"])
            chdir = root / chan_folder
            chdir.mkdir(parents=True, exist_ok=True)

            title = safename(meta["title"])
            (chdir / f"{title}.m3u").write_text(watch_url_for_playlist(meta["url"]) + "\n", encoding="utf-8")
            say(f"    • wrote {chan_folder}/{title}.m3u")

            # playlist thumb
            img_abs = ""
            if meta.get("thumb"):
                img_abs = str((dlroot / chan_folder / f"{title}.jpg").resolve())
                ok = fetch_thumb_to_jpg(meta["thumb"], img_abs)
                say(f"    • thumb {'ok' if ok else 'fail'} -> {img_abs if ok else meta['thumb']}")

            # record folder name (no avatar here unless already set later)
            folders_meta.setdefault(chan_folder, {"name": meta["uploader"], "image_abs": ""})
            all_entries.append({"relpath": f"{chan_folder}/{title}.m3u", "name": title, "image_abs": img_abs})
            continue

        base = chan_base(entry)
        handle = base.rsplit("/",1)[-1].lstrip("@") or "channel"
        say(f"[{ci}/{total}] Channel: {handle}  ({base})")

        # List playlists
        pls = list_playlists_for_channel(base)
        n = len(pls)
        say(f"    • found {n} playlists")
        if n == 0:
            # Still try to put a folder avatar if we can
            chdir = root / safename(handle)
            chdir.mkdir(parents=True, exist_ok=True)
            av_url = get_channel_avatar_url(base)
            avatar_abs = ""
            if av_url:
                outp = chdir / "folder.jpg"
                if fetch_thumb_to_jpg(av_url, outp):
                    avatar_abs = str(outp.resolve())
                    say(f"      - avatar ok -> {avatar_abs}")
            folders_meta.setdefault(safename(handle), {"name": handle, "image_abs": avatar_abs})
            continue

        if MAX_PL_PER_CH > 0 and n > MAX_PL_PER_CH:
            pls = pls[:MAX_PL_PER_CH]
            say(f"    • capped to first {MAX_PL_PER_CH} playlists")

        chan_folder = safename(handle)
        chdir = root / chan_folder
        chdir.mkdir(parents=True, exist_ok=True)

        # Avatar
        av_url = get_channel_avatar_url(base)
        avatar_abs = ""
        if av_url:
            outp = chdir / "folder.jpg"
            ok = fetch_thumb_to_jpg(av_url, outp)
            avatar_abs = str(outp.resolve()) if ok else ""
            say(f"      - avatar {'ok' if ok else 'fail'} -> {avatar_abs or av_url}")

        # Determine a nicer display name for the folder (from uploader if available)
        disp_name = pls[0].get("uploader") or handle
        folders_meta[chan_folder] = {"name": disp_name, "image_abs": avatar_abs}

        # Each playlist
        seen = set()
        for i, p in enumerate(pls, 1):
            title = safename(p["title"])
            key = title.lower()
            if key in seen:
                suf = (p.get("playlist_id") or "")[:6]
                title = f"{title}-{suf}"
            seen.add(key)

            say(f"    [{i}/{len(pls)}] {title}")
            (chdir / f"{title}.m3u").write_text(watch_url_for_playlist(p["url"]) + "\n", encoding="utf-8")
            img_abs = ""
            if p.get("thumb"):
                img_abs = str((dlroot / chan_folder / f"{title}.jpg").resolve())
                ok = fetch_thumb_to_jpg(p["thumb"], img_abs)
                say(f"       • thumb {'ok' if ok else 'fail'} -> {img_abs if ok else p['thumb']}")
            all_entries.append({"relpath": f"{chan_folder}/{title}.m3u", "name": title, "image_abs": img_abs})

    write_root_gamelist(root, all_entries, folders_meta)
    say(f"[yt-sync] Done. Wrote {len(all_entries)} playlists and {len(folders_meta)} folders to {root/'gamelist.xml'}")
    return 0

if __name__ == "__main__":
    sys.exit(main())
